{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9HUGmxyH2iUc",
    "outputId": "e474449f-8ae5-4043-8f68-dd9ba04377a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: xlrd in /usr/local/lib/python3.7/dist-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xlrd -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cxxGUdO8L9fD",
    "outputId": "91fd4d4f-1531-48a0-be0d-00083505472a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (22.10.26)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.3)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nxXbMia-OyBO",
    "outputId": "49a71b53-25c6-47f8-a3e5-87ce536f84ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "from imblearn.datasets import make_imbalance\n",
    "\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "from nltk.stem import *\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional,Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from tensorflow.keras.losses import cosine_similarity\n",
    "\n",
    "\n",
    "from keras.utils.data_utils import pad_sequences\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wkSnlJKL2eyD"
   },
   "outputs": [],
   "source": [
    "ran=random.sample(range(1000, 100000), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwW_8VWMKQ2d",
    "outputId": "f9a96c1e-5c91-436b-f63d-95e4647cbdf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AFf7CN7mUVul"
   },
   "outputs": [],
   "source": [
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    - Remove entity mentions (eg. '@united')\n",
    "    - Correct errors (eg. '&amp;' to '&')\n",
    "    @param    text (str): a string to be processed.\n",
    "    @return   text (Str): the processed string.\n",
    "    \"\"\"\n",
    "    # Remove '@name'\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "    \n",
    "    # Remove URL\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    \n",
    "    # Remove Hashtag\n",
    "    text = re.sub(r\"#\\S+\", \"\", text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Remove non character \n",
    "    text=re.sub(r'[\\W_]+',' ', text)\n",
    "    text=deEmojify(text)\n",
    "\n",
    "    # Remove  number\n",
    "    text = re.sub(\" \\d+\", \" \", text)\n",
    "\n",
    "    text = re.sub(\"just\", \" \", text)\n",
    "    text = re.sub(\"right\", \" \", text)\n",
    "    '''\n",
    "\n",
    "\n",
    "    output = re.sub(r'\\s*[A-Za-z]+\\b', '' , text)\n",
    "    text = output.rstrip()\n",
    "\n",
    "    persian = ['۰', '۱', '۲', '۳', '۴', '۵', '۶', '۷', '۸', '۹'];\n",
    "    for u in persian:\n",
    "        text = re.sub(u, \"\", text);\n",
    "\n",
    "  \n",
    "    \n",
    "    #\n",
    "    #text = re.sub(\"کرونا\", \" \", text)\n",
    "    #text = re.sub(\"ویروس\", \" \", text)\n",
    "  \n",
    "    '''\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Lo6a3FjSTKrv"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Tue Aug 16 14:43:05 2022\n",
    "\n",
    "@author: behnam\n",
    "\"\"\"\n",
    "\n",
    "def flat_list(a):\n",
    "    aa=[]\n",
    "    for j in range(len(a)):\n",
    "        \n",
    "        aa=aa+a[j].split(',')\n",
    "    return aa    \n",
    "        \n",
    "def text_preprocessing2(text):\n",
    "    \"\"\"\n",
    "    - Remove entity mentions (eg. '@united')\n",
    "    - Correct errors (eg. '&amp;' to '&')\n",
    "    @param    text (str): a string to be processed.\n",
    "    @return   text (Str): the processed string.\n",
    "    \"\"\"\n",
    "    # Remove '@name'\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '', text)\n",
    "    \n",
    "    # Remove URL\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    \n",
    "    # Remove Hashtag\n",
    "    text = re.sub(r\"#\\S+\", \"\", text)\n",
    "    \n",
    "    # Remove Hashtag\n",
    "    text = re.sub(r\"&\\S+\", \"\", text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    text=re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
    "\n",
    "    return text\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    text=re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WukUW7uHMFe8"
   },
   "outputs": [],
   "source": [
    "pmfd=pd.read_excel('./drive/MyDrive/balanced_pmftc.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "tPz_30j_iF0G"
   },
   "outputs": [],
   "source": [
    "ff='Authority'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "mAQD3Sh0fvLR"
   },
   "outputs": [],
   "source": [
    "foundation_annot_inClass=pmfd[pmfd['Label']==ff]\n",
    "foundation_annot_outClass=pmfd[pmfd['Label']!=ff]\n",
    "x_inClass=foundation_annot_inClass['Tweet']\n",
    "x_outClass=foundation_annot_outClass['Tweet']\n",
    "y_inClass=len(x_inClass)*[1]\n",
    "y_outClass=len(x_outClass)*[0]\n",
    "x=x_inClass.tolist()+x_outClass.tolist()\n",
    "y=y_inClass+y_outClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "deGCH3X1rZj1",
    "outputId": "144dd784-1b06-4256-8a70-80f4f15b8941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 7500, 1: 500})\n",
      "Resampled dataset shape Counter({0: 500, 1: 500})\n"
     ]
    }
   ],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "#rus = RandomUnderSampler(sampling_strategy={0: 500, 1: 500 },random_state=42)\n",
    "x_res, y_res = rus.fit_resample(np.asarray(x).reshape(-1, 1),y)\n",
    "\n",
    "print('Original dataset shape %s' % Counter(y))\n",
    "print('Resampled dataset shape %s' % Counter(y_res))\n",
    "\n",
    "x_res=x_res.reshape(len(x_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NA61zbBY9kWN"
   },
   "source": [
    "Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "WZpA2vCTBvoW"
   },
   "outputs": [],
   "source": [
    "stop_words=[]\n",
    "#with open('./drive/MyDrive/stop-words.txt') as file:\n",
    "with open('./drive/MyDrive/Pesian_Stop_Words_List.txt') as file:  \n",
    "\n",
    "    for line in file:\n",
    "      stop_words.append(line.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NzbPJszDehn",
    "outputId": "7191ffb5-cded-4c2e-aacb-c394e8ba69a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 3200.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "word_seq=[]\n",
    "sw_removed_texts = []\n",
    "for doc in tqdm(x_res):\n",
    "  tokens = word_tokenize(doc)\n",
    "  filtered = [word for word in tokens if word not in stop_words] \n",
    "  #sw_removed_texts.append(\" \".join(filtered))\n",
    "  word_seq.append(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m_hOWcM8Iwrr",
    "outputId": "97535990-7ba7-4b40-b36c-a7ad50048e37"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 3110.15it/s]\n"
     ]
    }
   ],
   "source": [
    "max_seq_len=120\n",
    "MAX_NB_WORDS=100000\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "sw_removed_texts = []\n",
    "for doc in tqdm(x_res):\n",
    "  tokens = word_tokenize(doc)\n",
    "  filtered = [word for word in tokens if word not in stop_words]\n",
    "  sw_removed_texts.append(\" \".join(filtered))\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=True, char_level=False)\n",
    "tokenizer.fit_on_texts(sw_removed_texts)  \n",
    "word_seq = tokenizer.texts_to_sequences(sw_removed_texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "word_seq= pad_sequences(word_seq, maxlen=max_seq_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDUNf81bl7xC",
    "outputId": "fc461243-e380-4a5c-ff3c-50b7f1ab11f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  195, 1154, 2085],\n",
       "       [   0,    0,    0, ..., 2090, 1156,   28],\n",
       "       [   0,    0,    0, ...,    0, 2091, 1157],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 6233, 6234,  219],\n",
       "       [   0,    0,    0, ..., 6235, 1078,  123],\n",
       "       [   0,    0,    0, ..., 6240,  715, 2083]], dtype=int32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "YoHIaYkntpaS"
   },
   "outputs": [],
   "source": [
    "def set_reproducible(seed):\n",
    "  \n",
    "\n",
    "  os.environ['PYTHONHASHSEED'] = str(0)\n",
    "  # For working on GPUs from \"TensorFlow Determinism\"\n",
    "  os.environ['CUDA_VISBLE_DEVICE'] = ''\n",
    "  #np.random.seed(seed)\n",
    "  random.seed(seed)\n",
    "  tf.random.set_seed(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "wZbZx08WgAg2"
   },
   "outputs": [],
   "source": [
    "nb_words = min(MAX_NB_WORDS, len(word_index)+1)\n",
    "embed_dim=64\n",
    "\n",
    "def get_model():\n",
    "  \n",
    "  model = tf.keras.Sequential()\n",
    "\n",
    "  model.add(Embedding(nb_words, embed_dim, input_length=max_seq_len,trainable=True))\n",
    "  model.add(tf.keras.layers.LayerNormalization(axis=1)) \n",
    "  model.add(Bidirectional(LSTM(16, return_sequences= False)))\n",
    "  #model.add(Bidirectional(LSTM(8, return_sequences= False)))\n",
    "  model.add(Dense(64,activation='relu'))\n",
    "  model.add(Dropout(0.3))\n",
    "  model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "  #model.summary()\n",
    "\n",
    "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  es_callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "id": "NgYTujB2W1hV",
    "outputId": "dbfe8940-9ad6-4452-c974-bb9a18c301f1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nf_binary_all=[]\\nf_macro_all=[]\\nf_micro_all=[]\\np_all =[]\\nr_all=[]\\nfold = 0\\n\\n\\nfor k in ran:\\n\\n  fold+=1\\n  x_train_a, x_test_a, y_train_a, y_test_a =train_test_split(word_seq,np.asanyarray(y_res), test_size=0.1, random_state=k)\\n\\n  set_reproducible(k)\\n  model=get_model()\\n  es_callback = EarlyStopping(monitor=\\'val_loss\\', patience=3)\\n  history = model.fit(x_train_a, y_train_a, batch_size=32, epochs=200,verbose=1, validation_split=0.2, callbacks=[es_callback], shuffle=True)\\n\\n  yhat=model.predict(x_test_a, verbose=0)\\n\\n  yp=[]\\n  for k in range(len(yhat)):\\n    if yhat[k][0]>0.45:\\n      yp.append(1)\\n    else:\\n      yp.append(0)\\n\\n  print(classification_report(y_test_a,yp))   \\n  print(\\'F1-score for fold: %d :\\' %fold)\\n  f1_macro=f1_score(y_test_a,yp,average=\\'macro\\')\\n  f1_binary=f1_score(y_test_a,yp,average=\\'binary\\')\\n  f1_micro=f1_score(y_test_a,yp,average=\\'micro\\')\\n\\n  print(f1_binary)\\n  print(\\'-----\\') \\n  f_binary_all.append(f1_binary)\\n\\n  print(f1_macro)\\n  print(\\'-----\\') \\n  f_macro_all.append(f1_macro)\\n\\n  print(f1_micro)\\n  print(\\'-----\\') \\n  f_micro_all.append(f1_micro)\\n\\n  print(\\'Recall-score for fold: %d :\\' %fold)\\n  r=recall_score(y_test_a,yp)\\n  print(r)\\n  print(\\'-----\\')\\n  print(\\'Precision-score for fold: %d :\\' %fold)\\n  p=precision_score(y_test_a,yp)\\n  print(p)\\n  print(\\'-----\\')\\n  print(\\'----------------------------------------------\\')\\n\\n  r_all.append(r)\\n  p_all.append(p)\\n \\n\\nprint(\"Average of F1_binary_Score = {}\".format(np.mean(f_binary_all)))\\nprint(\"Standard Deviation of F1_binary_Score = {}\".format(np.std(f_binary_all)))\\nprint(\\'------\\')\\n\\nprint(\"Average of F1_macro_Score = {}\".format(np.mean(f_macro_all)))\\nprint(\"Standard Deviation of F1_macro_Score = {}\".format(np.std(f_macro_all)))\\nprint(\\'------\\')\\n\\nprint(\"Average of F1_micro_Score = {}\".format(np.mean(f_micro_all)))\\nprint(\"Standard Deviation of F1_micro_Score = {}\".format(np.std(f_micro_all)))\\nprint(\\'------\\')\\n\\nprint(\"Average of Recall_Score = {}\".format(np.mean(r_all)))\\nprint(\"Standard Deviation of Recall_Score = {}\".format(np.std(r_all)))\\nprint(\\'------\\')\\n\\nprint(\"Average of Precision_Score = {}\".format(np.mean(p_all)))\\nprint(\"Standard Deviation of Precision_Score = {}\".format(np.std(p_all)))\\nprint(\\'------\\')\\n\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "f_binary_all=[]\n",
    "f_macro_all=[]\n",
    "f_micro_all=[]\n",
    "p_all =[]\n",
    "r_all=[]\n",
    "fold = 0\n",
    "\n",
    "\n",
    "for k in ran:\n",
    "\n",
    "  fold+=1\n",
    "  x_train_a, x_test_a, y_train_a, y_test_a =train_test_split(word_seq,np.asanyarray(y_res), test_size=0.1, random_state=k)\n",
    "\n",
    "  set_reproducible(k)\n",
    "  model=get_model()\n",
    "  es_callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "  history = model.fit(x_train_a, y_train_a, batch_size=32, epochs=200,verbose=1, validation_split=0.2, callbacks=[es_callback], shuffle=True)\n",
    "\n",
    "  yhat=model.predict(x_test_a, verbose=0)\n",
    "\n",
    "  yp=[]\n",
    "  for k in range(len(yhat)):\n",
    "    if yhat[k][0]>0.45:\n",
    "      yp.append(1)\n",
    "    else:\n",
    "      yp.append(0)\n",
    "\n",
    "  print(classification_report(y_test_a,yp))   \n",
    "  print('F1-score for fold: %d :' %fold)\n",
    "  f1_macro=f1_score(y_test_a,yp,average='macro')\n",
    "  f1_binary=f1_score(y_test_a,yp,average='binary')\n",
    "  f1_micro=f1_score(y_test_a,yp,average='micro')\n",
    "\n",
    "  print(f1_binary)\n",
    "  print('-----') \n",
    "  f_binary_all.append(f1_binary)\n",
    "\n",
    "  print(f1_macro)\n",
    "  print('-----') \n",
    "  f_macro_all.append(f1_macro)\n",
    "\n",
    "  print(f1_micro)\n",
    "  print('-----') \n",
    "  f_micro_all.append(f1_micro)\n",
    "\n",
    "  print('Recall-score for fold: %d :' %fold)\n",
    "  r=recall_score(y_test_a,yp)\n",
    "  print(r)\n",
    "  print('-----')\n",
    "  print('Precision-score for fold: %d :' %fold)\n",
    "  p=precision_score(y_test_a,yp)\n",
    "  print(p)\n",
    "  print('-----')\n",
    "  print('----------------------------------------------')\n",
    "\n",
    "  r_all.append(r)\n",
    "  p_all.append(p)\n",
    " \n",
    "\n",
    "print(\"Average of F1_binary_Score = {}\".format(np.mean(f_binary_all)))\n",
    "print(\"Standard Deviation of F1_binary_Score = {}\".format(np.std(f_binary_all)))\n",
    "print('------')\n",
    "\n",
    "print(\"Average of F1_macro_Score = {}\".format(np.mean(f_macro_all)))\n",
    "print(\"Standard Deviation of F1_macro_Score = {}\".format(np.std(f_macro_all)))\n",
    "print('------')\n",
    "\n",
    "print(\"Average of F1_micro_Score = {}\".format(np.mean(f_micro_all)))\n",
    "print(\"Standard Deviation of F1_micro_Score = {}\".format(np.std(f_micro_all)))\n",
    "print('------')\n",
    "\n",
    "print(\"Average of Recall_Score = {}\".format(np.mean(r_all)))\n",
    "print(\"Standard Deviation of Recall_Score = {}\".format(np.std(r_all)))\n",
    "print('------')\n",
    "\n",
    "print(\"Average of Precision_Score = {}\".format(np.mean(p_all)))\n",
    "print(\"Standard Deviation of Precision_Score = {}\".format(np.std(p_all)))\n",
    "print('------')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rzwojx0isFkq",
    "outputId": "2ddb597d-6371-4aa1-8452-590ed68a74b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "57/57 [==============================] - 8s 67ms/step - loss: 1.1374 - accuracy: 0.5011 - val_loss: 0.6984 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "57/57 [==============================] - 3s 51ms/step - loss: 0.8399 - accuracy: 0.4633 - val_loss: 0.6979 - val_accuracy: 0.5200\n",
      "Epoch 3/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.7241 - accuracy: 0.4722 - val_loss: 0.6982 - val_accuracy: 0.5200\n",
      "Epoch 4/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.5922 - accuracy: 0.7233 - val_loss: 0.7154 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.3560 - accuracy: 0.9144 - val_loss: 1.0152 - val_accuracy: 0.4900\n",
      "Epoch 6/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.1642 - accuracy: 0.9667 - val_loss: 1.0448 - val_accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0534 - accuracy: 0.9967 - val_loss: 0.8681 - val_accuracy: 0.6300\n",
      "Epoch 8/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.9515 - val_accuracy: 0.6400\n",
      "Epoch 9/200\n",
      "57/57 [==============================] - 3s 51ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.9548 - val_accuracy: 0.6700\n",
      "Epoch 10/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0016 - val_accuracy: 0.6700\n",
      "Epoch 11/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.0344 - val_accuracy: 0.6800\n",
      "Epoch 12/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.0840 - val_accuracy: 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:46, 46.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.50      0.60        50\n",
      "           1       0.63      0.84      0.72        50\n",
      "\n",
      "    accuracy                           0.67       100\n",
      "   macro avg       0.69      0.67      0.66       100\n",
      "weighted avg       0.69      0.67      0.66       100\n",
      "\n",
      "F1_binary-score for fold: 0 :\n",
      "0.7179487179487181\n",
      "-----\n",
      "F1_macro-score for fold: 0 :\n",
      "0.6601791782514674\n",
      "-----\n",
      "Recall-score for fold: 0 :\n",
      "0.84\n",
      "-----\n",
      "Precision-score for fold: 0 :\n",
      "0.6268656716417911\n",
      "-----\n",
      "----------------------------------------------\n",
      "Epoch 1/200\n",
      "57/57 [==============================] - 10s 88ms/step - loss: 1.1569 - accuracy: 0.5489 - val_loss: 0.6956 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "57/57 [==============================] - 4s 73ms/step - loss: 0.7615 - accuracy: 0.3578 - val_loss: 0.6980 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "57/57 [==============================] - 3s 59ms/step - loss: 0.7534 - accuracy: 0.3722 - val_loss: 0.6885 - val_accuracy: 0.5200\n",
      "Epoch 4/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.6466 - accuracy: 0.6178 - val_loss: 0.6913 - val_accuracy: 0.5300\n",
      "Epoch 5/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.5079 - accuracy: 0.8267 - val_loss: 0.7431 - val_accuracy: 0.5500\n",
      "Epoch 6/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.2649 - accuracy: 0.9544 - val_loss: 1.0399 - val_accuracy: 0.5300\n",
      "Epoch 7/200\n",
      "57/57 [==============================] - 3s 51ms/step - loss: 0.0972 - accuracy: 0.9800 - val_loss: 0.7371 - val_accuracy: 0.6400\n",
      "Epoch 8/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0280 - accuracy: 0.9989 - val_loss: 0.7590 - val_accuracy: 0.6700\n",
      "Epoch 9/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.8553 - val_accuracy: 0.6700\n",
      "Epoch 10/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.8057 - val_accuracy: 0.6800\n",
      "Epoch 11/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.8377 - val_accuracy: 0.6700\n",
      "Epoch 12/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.8797 - val_accuracy: 0.6800\n",
      "Epoch 13/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.0175 - val_accuracy: 0.6700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:35, 47.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.52      0.62        50\n",
      "           1       0.64      0.84      0.72        50\n",
      "\n",
      "    accuracy                           0.68       100\n",
      "   macro avg       0.70      0.68      0.67       100\n",
      "weighted avg       0.70      0.68      0.67       100\n",
      "\n",
      "F1_binary-score for fold: 1 :\n",
      "0.7241379310344828\n",
      "-----\n",
      "F1_macro-score for fold: 1 :\n",
      "0.6715927750410509\n",
      "-----\n",
      "Recall-score for fold: 1 :\n",
      "0.84\n",
      "-----\n",
      "Precision-score for fold: 1 :\n",
      "0.6363636363636364\n",
      "-----\n",
      "----------------------------------------------\n",
      "Epoch 1/200\n",
      "57/57 [==============================] - 9s 88ms/step - loss: 0.9279 - accuracy: 0.4300 - val_loss: 0.6796 - val_accuracy: 0.6700\n",
      "Epoch 2/200\n",
      "57/57 [==============================] - 4s 70ms/step - loss: 0.7318 - accuracy: 0.3656 - val_loss: 0.6823 - val_accuracy: 0.6900\n",
      "Epoch 3/200\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 0.6617 - accuracy: 0.6278 - val_loss: 0.7210 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.5897 - accuracy: 0.6456 - val_loss: 0.8613 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "57/57 [==============================] - 4s 75ms/step - loss: 0.3634 - accuracy: 0.8689 - val_loss: 1.1323 - val_accuracy: 0.5300\n",
      "Epoch 6/200\n",
      "57/57 [==============================] - 4s 69ms/step - loss: 0.1126 - accuracy: 0.9856 - val_loss: 0.7849 - val_accuracy: 0.6300\n",
      "Epoch 7/200\n",
      "57/57 [==============================] - 3s 55ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.8867 - val_accuracy: 0.6300\n",
      "Epoch 8/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.9722 - val_accuracy: 0.6500\n",
      "Epoch 9/200\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.0510 - val_accuracy: 0.6600\n",
      "Epoch 10/200\n",
      "57/57 [==============================] - 5s 93ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.1245 - val_accuracy: 0.6600\n",
      "Epoch 11/200\n",
      "57/57 [==============================] - 6s 113ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.1836 - val_accuracy: 0.6700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [03:02, 65.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.69        50\n",
      "           1       0.69      0.58      0.63        50\n",
      "\n",
      "    accuracy                           0.66       100\n",
      "   macro avg       0.66      0.66      0.66       100\n",
      "weighted avg       0.66      0.66      0.66       100\n",
      "\n",
      "F1_binary-score for fold: 2 :\n",
      "0.6304347826086957\n",
      "-----\n",
      "F1_macro-score for fold: 2 :\n",
      "0.6578099838969405\n",
      "-----\n",
      "Recall-score for fold: 2 :\n",
      "0.58\n",
      "-----\n",
      "Precision-score for fold: 2 :\n",
      "0.6904761904761905\n",
      "-----\n",
      "----------------------------------------------\n",
      "Epoch 1/200\n",
      "57/57 [==============================] - 9s 67ms/step - loss: 1.1157 - accuracy: 0.5344 - val_loss: 0.6848 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.7876 - accuracy: 0.3067 - val_loss: 0.6862 - val_accuracy: 0.5400\n",
      "Epoch 3/200\n",
      "57/57 [==============================] - 3s 51ms/step - loss: 0.6774 - accuracy: 0.5700 - val_loss: 0.6792 - val_accuracy: 0.5600\n",
      "Epoch 4/200\n",
      "57/57 [==============================] - 3s 60ms/step - loss: 0.5700 - accuracy: 0.7789 - val_loss: 0.7478 - val_accuracy: 0.5100\n",
      "Epoch 5/200\n",
      "57/57 [==============================] - 3s 56ms/step - loss: 0.3761 - accuracy: 0.8856 - val_loss: 1.0590 - val_accuracy: 0.5500\n",
      "Epoch 6/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.1817 - accuracy: 0.9633 - val_loss: 0.9031 - val_accuracy: 0.5700\n",
      "Epoch 7/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0570 - accuracy: 0.9933 - val_loss: 0.9904 - val_accuracy: 0.5700\n",
      "Epoch 8/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0248 - accuracy: 0.9978 - val_loss: 1.0341 - val_accuracy: 0.6100\n",
      "Epoch 9/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.0716 - val_accuracy: 0.6200\n",
      "Epoch 10/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.1412 - val_accuracy: 0.6300\n",
      "Epoch 11/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1874 - val_accuracy: 0.6300\n",
      "Epoch 12/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.2326 - val_accuracy: 0.6300\n",
      "Epoch 13/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.3042 - val_accuracy: 0.6100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [03:49, 58.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.54      0.59        50\n",
      "           1       0.60      0.70      0.65        50\n",
      "\n",
      "    accuracy                           0.62       100\n",
      "   macro avg       0.62      0.62      0.62       100\n",
      "weighted avg       0.62      0.62      0.62       100\n",
      "\n",
      "F1_binary-score for fold: 3 :\n",
      "0.6481481481481481\n",
      "-----\n",
      "F1_macro-score for fold: 3 :\n",
      "0.6175523349436394\n",
      "-----\n",
      "Recall-score for fold: 3 :\n",
      "0.7\n",
      "-----\n",
      "Precision-score for fold: 3 :\n",
      "0.603448275862069\n",
      "-----\n",
      "----------------------------------------------\n",
      "Epoch 1/200\n",
      "57/57 [==============================] - 9s 68ms/step - loss: 1.0472 - accuracy: 0.4922 - val_loss: 0.6931 - val_accuracy: 0.5400\n",
      "Epoch 2/200\n",
      "57/57 [==============================] - 3s 51ms/step - loss: 0.7694 - accuracy: 0.4322 - val_loss: 0.7083 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "57/57 [==============================] - 3s 60ms/step - loss: 0.7737 - accuracy: 0.3189 - val_loss: 0.6892 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.6413 - accuracy: 0.6333 - val_loss: 0.7633 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.6929 - accuracy: 0.5878 - val_loss: 0.6608 - val_accuracy: 0.6100\n",
      "Epoch 6/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.3645 - accuracy: 0.9411 - val_loss: 0.9344 - val_accuracy: 0.5500\n",
      "Epoch 7/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.1700 - accuracy: 0.9700 - val_loss: 0.9860 - val_accuracy: 0.5700\n",
      "Epoch 8/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0537 - accuracy: 0.9956 - val_loss: 0.6243 - val_accuracy: 0.7300\n",
      "Epoch 9/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0166 - accuracy: 0.9989 - val_loss: 0.6747 - val_accuracy: 0.7200\n",
      "Epoch 10/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.7300\n",
      "Epoch 11/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.8063 - val_accuracy: 0.7100\n",
      "Epoch 12/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8731 - val_accuracy: 0.7300\n",
      "Epoch 13/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8940 - val_accuracy: 0.7300\n",
      "Epoch 14/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9405 - val_accuracy: 0.7400\n",
      "Epoch 15/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9912 - val_accuracy: 0.7300\n",
      "Epoch 16/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0332 - val_accuracy: 0.7200\n",
      "Epoch 17/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0665 - val_accuracy: 0.7300\n",
      "Epoch 18/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 8.1339e-04 - accuracy: 1.0000 - val_loss: 1.1372 - val_accuracy: 0.7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [04:53, 60.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.78      0.74        50\n",
      "           1       0.76      0.68      0.72        50\n",
      "\n",
      "    accuracy                           0.73       100\n",
      "   macro avg       0.73      0.73      0.73       100\n",
      "weighted avg       0.73      0.73      0.73       100\n",
      "\n",
      "F1_binary-score for fold: 4 :\n",
      "0.7157894736842104\n",
      "-----\n",
      "F1_macro-score for fold: 4 :\n",
      "0.7293233082706766\n",
      "-----\n",
      "Recall-score for fold: 4 :\n",
      "0.68\n",
      "-----\n",
      "Precision-score for fold: 4 :\n",
      "0.7555555555555555\n",
      "-----\n",
      "----------------------------------------------\n",
      "Epoch 1/200\n",
      "57/57 [==============================] - 8s 67ms/step - loss: 1.0491 - accuracy: 0.4889 - val_loss: 0.6903 - val_accuracy: 0.5300\n",
      "Epoch 2/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.7363 - accuracy: 0.4689 - val_loss: 0.7040 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "57/57 [==============================] - 4s 64ms/step - loss: 0.7245 - accuracy: 0.4211 - val_loss: 0.6840 - val_accuracy: 0.5400\n",
      "Epoch 4/200\n",
      "57/57 [==============================] - 5s 79ms/step - loss: 0.5377 - accuracy: 0.7811 - val_loss: 0.9645 - val_accuracy: 0.5100\n",
      "Epoch 5/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.3891 - accuracy: 0.8489 - val_loss: 0.7724 - val_accuracy: 0.5600\n",
      "Epoch 6/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.1563 - accuracy: 0.9833 - val_loss: 0.6160 - val_accuracy: 0.6700\n",
      "Epoch 7/200\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 0.0442 - accuracy: 0.9967 - val_loss: 0.6528 - val_accuracy: 0.7100\n",
      "Epoch 8/200\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.6984 - val_accuracy: 0.7300\n",
      "Epoch 9/200\n",
      "57/57 [==============================] - 3s 55ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.7519 - val_accuracy: 0.7200\n",
      "Epoch 10/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.7969 - val_accuracy: 0.7400\n",
      "Epoch 11/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.8264 - val_accuracy: 0.7000\n",
      "Epoch 12/200\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.8672 - val_accuracy: 0.6800\n",
      "Epoch 13/200\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9063 - val_accuracy: 0.6900\n",
      "Epoch 14/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.9343 - val_accuracy: 0.7000\n",
      "Epoch 15/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 9.3889e-04 - accuracy: 1.0000 - val_loss: 0.9597 - val_accuracy: 0.7000\n",
      "Epoch 16/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 8.0828e-04 - accuracy: 1.0000 - val_loss: 0.9737 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [06:20, 69.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.82      0.75        50\n",
      "           1       0.78      0.62      0.69        50\n",
      "\n",
      "    accuracy                           0.72       100\n",
      "   macro avg       0.73      0.72      0.72       100\n",
      "weighted avg       0.73      0.72      0.72       100\n",
      "\n",
      "F1_binary-score for fold: 5 :\n",
      "0.6888888888888889\n",
      "-----\n",
      "F1_macro-score for fold: 5 :\n",
      "0.7171717171717171\n",
      "-----\n",
      "Recall-score for fold: 5 :\n",
      "0.62\n",
      "-----\n",
      "Precision-score for fold: 5 :\n",
      "0.775\n",
      "-----\n",
      "----------------------------------------------\n",
      "Epoch 1/200\n",
      "57/57 [==============================] - 9s 69ms/step - loss: 1.1130 - accuracy: 0.4989 - val_loss: 0.6783 - val_accuracy: 0.6900\n",
      "Epoch 2/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.6877 - accuracy: 0.5333 - val_loss: 0.7226 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.7786 - accuracy: 0.3700 - val_loss: 0.6711 - val_accuracy: 0.5600\n",
      "Epoch 4/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.5263 - accuracy: 0.8367 - val_loss: 0.6724 - val_accuracy: 0.5500\n",
      "Epoch 5/200\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 0.3300 - accuracy: 0.9133 - val_loss: 0.8352 - val_accuracy: 0.5700\n",
      "Epoch 6/200\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 0.1413 - accuracy: 0.9778 - val_loss: 0.5552 - val_accuracy: 0.7400\n",
      "Epoch 7/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.5600 - val_accuracy: 0.7700\n",
      "Epoch 8/200\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.5768 - val_accuracy: 0.7600\n",
      "Epoch 9/200\n",
      "57/57 [==============================] - 3s 55ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.6049 - val_accuracy: 0.7500\n",
      "Epoch 10/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.6625 - val_accuracy: 0.7500\n",
      "Epoch 11/200\n",
      "57/57 [==============================] - 3s 56ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.7361 - val_accuracy: 0.7500\n",
      "Epoch 12/200\n",
      "57/57 [==============================] - 5s 88ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8003 - val_accuracy: 0.7400\n",
      "Epoch 13/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8806 - val_accuracy: 0.7300\n",
      "Epoch 14/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9168 - val_accuracy: 0.7200\n",
      "Epoch 15/200\n",
      "57/57 [==============================] - 4s 72ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.9290 - val_accuracy: 0.7500\n",
      "Epoch 16/200\n",
      "57/57 [==============================] - 4s 70ms/step - loss: 7.3095e-04 - accuracy: 1.0000 - val_loss: 0.9252 - val_accuracy: 0.7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [07:48, 75.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.82      0.77        50\n",
      "           1       0.80      0.70      0.74        50\n",
      "\n",
      "    accuracy                           0.76       100\n",
      "   macro avg       0.76      0.76      0.76       100\n",
      "weighted avg       0.76      0.76      0.76       100\n",
      "\n",
      "F1_binary-score for fold: 6 :\n",
      "0.7446808510638298\n",
      "-----\n",
      "F1_macro-score for fold: 6 :\n",
      "0.7591328783621035\n",
      "-----\n",
      "Recall-score for fold: 6 :\n",
      "0.7\n",
      "-----\n",
      "Precision-score for fold: 6 :\n",
      "0.7954545454545454\n",
      "-----\n",
      "----------------------------------------------\n",
      "Epoch 1/200\n",
      "57/57 [==============================] - 8s 66ms/step - loss: 1.1247 - accuracy: 0.5056 - val_loss: 0.6855 - val_accuracy: 0.5400\n",
      "Epoch 2/200\n",
      "57/57 [==============================] - 3s 51ms/step - loss: 0.7691 - accuracy: 0.3700 - val_loss: 0.6865 - val_accuracy: 0.5200\n",
      "Epoch 3/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.6535 - accuracy: 0.6233 - val_loss: 0.7547 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.6862 - accuracy: 0.5367 - val_loss: 0.6706 - val_accuracy: 0.5600\n",
      "Epoch 5/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.3923 - accuracy: 0.9256 - val_loss: 1.0582 - val_accuracy: 0.5300\n",
      "Epoch 6/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.2012 - accuracy: 0.9556 - val_loss: 0.9387 - val_accuracy: 0.6000\n",
      "Epoch 7/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0591 - accuracy: 0.9933 - val_loss: 0.6899 - val_accuracy: 0.6600\n",
      "Epoch 8/200\n",
      "57/57 [==============================] - 5s 85ms/step - loss: 0.0168 - accuracy: 0.9989 - val_loss: 0.7933 - val_accuracy: 0.6600\n",
      "Epoch 9/200\n",
      "57/57 [==============================] - 4s 69ms/step - loss: 0.0099 - accuracy: 0.9989 - val_loss: 0.8443 - val_accuracy: 0.6500\n",
      "Epoch 10/200\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.8932 - val_accuracy: 0.6800\n",
      "Epoch 11/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.9330 - val_accuracy: 0.6900\n",
      "Epoch 12/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.9652 - val_accuracy: 0.6800\n",
      "Epoch 13/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.0009 - val_accuracy: 0.6800\n",
      "Epoch 14/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.0366 - val_accuracy: 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [09:15, 79.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.78      0.71        50\n",
      "           1       0.72      0.58      0.64        50\n",
      "\n",
      "    accuracy                           0.68       100\n",
      "   macro avg       0.69      0.68      0.68       100\n",
      "weighted avg       0.69      0.68      0.68       100\n",
      "\n",
      "F1_binary-score for fold: 7 :\n",
      "0.6444444444444445\n",
      "-----\n",
      "F1_macro-score for fold: 7 :\n",
      "0.6767676767676767\n",
      "-----\n",
      "Recall-score for fold: 7 :\n",
      "0.58\n",
      "-----\n",
      "Precision-score for fold: 7 :\n",
      "0.725\n",
      "-----\n",
      "----------------------------------------------\n",
      "Epoch 1/200\n",
      "57/57 [==============================] - 10s 102ms/step - loss: 1.0638 - accuracy: 0.4744 - val_loss: 0.6866 - val_accuracy: 0.5700\n",
      "Epoch 2/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.7177 - accuracy: 0.5056 - val_loss: 0.7068 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.7387 - accuracy: 0.4100 - val_loss: 0.6706 - val_accuracy: 0.7300\n",
      "Epoch 4/200\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 0.5406 - accuracy: 0.8067 - val_loss: 0.7735 - val_accuracy: 0.5200\n",
      "Epoch 5/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.3452 - accuracy: 0.8811 - val_loss: 0.8293 - val_accuracy: 0.5500\n",
      "Epoch 6/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.1424 - accuracy: 0.9789 - val_loss: 0.6055 - val_accuracy: 0.6800\n",
      "Epoch 7/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0357 - accuracy: 0.9989 - val_loss: 0.6985 - val_accuracy: 0.7400\n",
      "Epoch 8/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.7640 - val_accuracy: 0.7000\n",
      "Epoch 9/200\n",
      "57/57 [==============================] - 3s 55ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.8257 - val_accuracy: 0.6900\n",
      "Epoch 10/200\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.8666 - val_accuracy: 0.6800\n",
      "Epoch 11/200\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.9100 - val_accuracy: 0.6900\n",
      "Epoch 12/200\n",
      "57/57 [==============================] - 3s 55ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.9460 - val_accuracy: 0.7000\n",
      "Epoch 13/200\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.9701 - val_accuracy: 0.6900\n",
      "Epoch 14/200\n",
      "57/57 [==============================] - 3s 55ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0251 - val_accuracy: 0.7000\n",
      "Epoch 15/200\n",
      "57/57 [==============================] - 3s 55ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0506 - val_accuracy: 0.6900\n",
      "Epoch 16/200\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 9.6806e-04 - accuracy: 1.0000 - val_loss: 1.0745 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [10:43, 81.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.74      0.70        50\n",
      "           1       0.70      0.62      0.66        50\n",
      "\n",
      "    accuracy                           0.68       100\n",
      "   macro avg       0.68      0.68      0.68       100\n",
      "weighted avg       0.68      0.68      0.68       100\n",
      "\n",
      "F1_binary-score for fold: 8 :\n",
      "0.6595744680851063\n",
      "-----\n",
      "F1_macro-score for fold: 8 :\n",
      "0.6788438378161381\n",
      "-----\n",
      "Recall-score for fold: 8 :\n",
      "0.62\n",
      "-----\n",
      "Precision-score for fold: 8 :\n",
      "0.7045454545454546\n",
      "-----\n",
      "----------------------------------------------\n",
      "Epoch 1/200\n",
      "57/57 [==============================] - 10s 71ms/step - loss: 1.0271 - accuracy: 0.4644 - val_loss: 0.6802 - val_accuracy: 0.6100\n",
      "Epoch 2/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.6776 - accuracy: 0.5589 - val_loss: 0.7670 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.7633 - accuracy: 0.4211 - val_loss: 0.6796 - val_accuracy: 0.5200\n",
      "Epoch 4/200\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 0.5521 - accuracy: 0.8211 - val_loss: 0.7642 - val_accuracy: 0.5300\n",
      "Epoch 5/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.3178 - accuracy: 0.9156 - val_loss: 1.4675 - val_accuracy: 0.5200\n",
      "Epoch 6/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.1165 - accuracy: 0.9833 - val_loss: 0.8297 - val_accuracy: 0.6300\n",
      "Epoch 7/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.9243 - val_accuracy: 0.6400\n",
      "Epoch 8/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.9701 - val_accuracy: 0.6300\n",
      "Epoch 9/200\n",
      "57/57 [==============================] - 3s 53ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.0012 - val_accuracy: 0.6600\n",
      "Epoch 10/200\n",
      "57/57 [==============================] - 3s 54ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.0190 - val_accuracy: 0.6500\n",
      "Epoch 11/200\n",
      "57/57 [==============================] - 3s 52ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0422 - val_accuracy: 0.6600\n",
      "Epoch 12/200\n",
      "57/57 [==============================] - 4s 64ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0662 - val_accuracy: 0.6500\n",
      "Epoch 13/200\n",
      "57/57 [==============================] - 6s 102ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.0884 - val_accuracy: 0.6700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [11:35, 69.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64        50\n",
      "           1       0.64      0.68      0.66        50\n",
      "\n",
      "    accuracy                           0.65       100\n",
      "   macro avg       0.65      0.65      0.65       100\n",
      "weighted avg       0.65      0.65      0.65       100\n",
      "\n",
      "F1_binary-score for fold: 9 :\n",
      "0.6601941747572816\n",
      "-----\n",
      "F1_macro-score for fold: 9 :\n",
      "0.6496847162446201\n",
      "-----\n",
      "Recall-score for fold: 9 :\n",
      "0.68\n",
      "-----\n",
      "Precision-score for fold: 9 :\n",
      "0.6415094339622641\n",
      "-----\n",
      "----------------------------------------------\n",
      "Average of F1_binary_Score = 0.6834241880663805\n",
      "Standard Deviation of F1_binary_Score = 0.037893857836442335\n",
      "------\n",
      "Average of F1_macro_Score = 0.681805840676603\n",
      "Standard Deviation of F1_binary_Score = 0.03978741292698332\n",
      "------\n",
      "Average of Recall_Score = 0.6839999999999999\n",
      "Standard Deviation of Recall_Score = 0.08890444308357147\n",
      "------\n",
      "Average of Precision_Score = 0.6954218763861506\n",
      "Standard Deviation of Precision_Score = 0.0636328220797583\n",
      "------\n",
      "nan\n",
      "[0.7179487179487181, 0.7241379310344828, 0.6304347826086957, 0.6481481481481481, 0.7157894736842104, 0.6888888888888889, 0.7446808510638298, 0.6444444444444445, 0.6595744680851063, 0.6601941747572816]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "split_num=10\n",
    "kf = StratifiedKFold(n_splits=split_num, shuffle=True, random_state=2022)\n",
    "\n",
    "f_binary_all=[]\n",
    "f_macro_all=[]\n",
    "p_all =[]\n",
    "r_all=[]\n",
    "fold = 0\n",
    "\n",
    "for train_idx, val_idx in tqdm(kf.split(word_seq,np.asarray(y_res))):\n",
    "\n",
    "   \n",
    "\n",
    "    x_train_f = word_seq[train_idx]\n",
    "    y_train_f = np.asarray(y_res)[train_idx]\n",
    "    x_val_f = word_seq[val_idx]\n",
    "    y_val_f =np.asarray(y_res)[val_idx]\n",
    "\n",
    "    set_reproducible(ran[fold])\n",
    "    model=get_model()\n",
    "    es_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    model.fit(x_train_f, y_train_f, batch_size=16, epochs=200,verbose=1, callbacks=[es_callback],validation_data=(x_val_f, y_val_f), shuffle=False)\n",
    "    #model.fit(x_train_f, y_train_f, batch_size=16, epochs=200,verbose=0,validation_data=(x_val_f, y_val_f), shuffle=False )\n",
    "\n",
    "    #model.fit(x_train_f, y_train_f, batch_size=32, epochs=200,verbose=0, callbacks=[es_callback],validation_split=0.1)\n",
    "\n",
    "\n",
    "\n",
    "    yhat=model.predict(x_val_f, verbose=0)\n",
    "\n",
    "    yp=[]\n",
    "    for k in range(len(yhat)):\n",
    "      if yhat[k][0]>0.45:\n",
    "        yp.append(1)\n",
    "      else:\n",
    "        yp.append(0)\n",
    "\n",
    "    print(classification_report(y_val_f,yp)) \n",
    "\n",
    "    print('F1_binary-score for fold: %d :' %fold)\n",
    "    f1_binary=f1_score(y_val_f,yp,average='binary')\n",
    "    print(f1_binary)\n",
    "    print('-----')\n",
    "\n",
    "    print('F1_macro-score for fold: %d :' %fold)\n",
    "    f1_macro=f1_score(y_val_f,yp,average='macro')\n",
    "    print(f1_macro)\n",
    "    print('-----')\n",
    "\n",
    "    print('Recall-score for fold: %d :' %fold)\n",
    "    r=recall_score(y_val_f,yp)\n",
    "    print(r)\n",
    "    print('-----')\n",
    "    print('Precision-score for fold: %d :' %fold)\n",
    "    p=precision_score(y_val_f,yp)\n",
    "    print(p)\n",
    "    print('-----')\n",
    "    print('----------------------------------------------')\n",
    "    f_binary_all.append(f1_binary)\n",
    "    f_macro_all.append(f1_macro)\n",
    "    r_all.append(r)\n",
    "    p_all.append(p)\n",
    "    fold+=1\n",
    "\n",
    "\n",
    "\n",
    "print(\"Average of F1_binary_Score = {}\".format(np.mean(f_binary_all)))\n",
    "print(\"Standard Deviation of F1_binary_Score = {}\".format(np.std(f_binary_all)))\n",
    "print('------')\n",
    "\n",
    "print(\"Average of F1_macro_Score = {}\".format(np.mean(f_macro_all)))\n",
    "print(\"Standard Deviation of F1_binary_Score = {}\".format(np.std(f_macro_all)))\n",
    "print('------')\n",
    "\n",
    "\n",
    "print(\"Average of Recall_Score = {}\".format(np.mean(r_all)))\n",
    "print(\"Standard Deviation of Recall_Score = {}\".format(np.std(r_all)))\n",
    "print('------')\n",
    "\n",
    "print(\"Average of Precision_Score = {}\".format(np.mean(p_all)))\n",
    "print(\"Standard Deviation of Precision_Score = {}\".format(np.std(p_all)))\n",
    "print('------')\n",
    "\n",
    "\n",
    "\n",
    "print(np.mean([k for k  in f_macro_all if k>0.79 ]))\n",
    "print(f_binary_all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "bh5zvqWPU05v"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
